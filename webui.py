# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Liu Yue)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
import sys
import argparse
import gradio as gr
import numpy as np
import torch
import torchaudio
import random
import librosa
import logging
import platform
import psutil
import GPUtil
import onnxruntime as ort


# ä»…åšæ—¥å¿—æç¤ºï¼Œä¸è°ƒç”¨ set_default_providers
if 'CUDAExecutionProvider' in ort.get_available_providers():
    logging.info("Using CUDA for onnxruntime")
    # æ·»åŠ  onnxruntime ä¼˜åŒ–é€‰é¡¹
    session_options = ort.SessionOptions()
    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    session_options.enable_mem_pattern = True
    session_options.enable_cpu_mem_arena = True
    session_options.log_severity_level = 1
else:
    logging.warning("CUDA not available for onnxruntime, using CPU")
    session_options = ort.SessionOptions()
    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    session_options.enable_mem_pattern = True
    session_options.enable_cpu_mem_arena = True
    session_options.log_severity_level = 1

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/third_party/Matcha-TTS'.format(ROOT_DIR))

# æ£€æŸ¥ ttsfrd æ˜¯å¦å¯ç”¨
try:
    import ttsfrd
    TTSFRD_AVAILABLE = True
except ImportError:
    TTSFRD_AVAILABLE = False
    logging.warning("ttsfrd package not available, using WeTextProcessing instead")

from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.utils.common import set_all_random_seed

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                   format='%(asctime)s - %(levelname)s - %(message)s')

# æ¨¡å‹é…ç½®
AVAILABLE_MODELS = {
    'CosyVoice-300M': 'pretrained_models/CosyVoice-300M',
    'CosyVoice-300M-SFT': 'pretrained_models/CosyVoice-300M-SFT',
    'CosyVoice-300M-Instruct': 'pretrained_models/CosyVoice-300M-Instruct',
    'CosyVoice2-0.5B': 'pretrained_models/CosyVoice2-0.5B'
}

inference_mode_list = ['é¢„è®­ç»ƒéŸ³è‰²', '3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»', 'è‡ªç„¶è¯­è¨€æ§åˆ¶']
instruct_dict = {'é¢„è®­ç»ƒéŸ³è‰²': '1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²\n2. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 '3sæé€Ÿå¤åˆ»': '1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. è¾“å…¥promptæ–‡æœ¬\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 'è·¨è¯­ç§å¤åˆ»': '1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®',
                 'è‡ªç„¶è¯­è¨€æ§åˆ¶': '1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²\n2. è¾“å…¥instructæ–‡æœ¬\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®'}
stream_mode_list = [('å¦', False), ('æ˜¯', True)]
max_val = 0.8

def check_ttsfrd_installation():
    """æ£€æŸ¥ ttsfrd å®‰è£…çŠ¶æ€å¹¶æä¾›å»ºè®®"""
    if not TTSFRD_AVAILABLE:
        system = platform.system()
        if system == "Windows":
            return """
            ttsfrd åŒ…æœªå®‰è£…æˆ–ä¸å¯ç”¨ã€‚å½“å‰ç³»ç»Ÿä¸º Windowsï¼Œä½†æä¾›çš„ ttsfrd wheel æ–‡ä»¶ä»…æ”¯æŒ Linuxã€‚
            ç³»ç»Ÿå°†ä½¿ç”¨ WeTextProcessing ä½œä¸ºæ›¿ä»£ã€‚
            
            æ³¨æ„ï¼šè¿™ä¸ä¼šå½±å“åŸºæœ¬åŠŸèƒ½ï¼Œä½†å¯èƒ½ä¼šå½±å“æŸäº›æ–‡æœ¬å¤„ç†ç‰¹æ€§ã€‚
            """
        else:
            return """
            ttsfrd åŒ…æœªå®‰è£…ã€‚è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š
            pip install pretrained_models/CosyVoice-ttsfrd/ttsfrd_dependency-0.1-py3-none-any.whl
            pip install pretrained_models/CosyVoice-ttsfrd/ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
            """
    return "ttsfrd åŒ…å·²æ­£ç¡®å®‰è£…"

def load_model(model_name):
    """åŠ è½½æŒ‡å®šçš„æ¨¡å‹"""
    model_path = AVAILABLE_MODELS.get(model_name)
    if not model_path:
        return None, "æ¨¡å‹ä¸å­˜åœ¨"
    
    if not os.path.exists(model_path):
        return None, f"æ¨¡å‹ç›®å½• {model_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹"
    
    try:
        logging.info(f"Attempting to load model from {model_path}")
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åŠ è½½æ–¹å¼
        if model_name == 'CosyVoice2-0.5B':
            model = CosyVoice2(model_path, load_jit=False, load_trt=False, fp16=False, use_flow_cache=True)
        else:
            model = CosyVoice(model_path, load_jit=False, load_trt=False, fp16=False)
        
        logging.info("Successfully loaded model")
        device_info = "CPU" if not torch.cuda.is_available() else f"GPU ({torch.cuda.get_device_name(0)})"
        
        # è·å–é¢„è®­ç»ƒéŸ³è‰²åˆ—è¡¨
        spk_list = model.list_available_spks()
        logging.info(f"Available speakers: {spk_list}")
        
        return model, f"æ¨¡å‹åŠ è½½æˆåŠŸ (ä½¿ç”¨{device_info}è¿›è¡Œæ¨ç†)"
    except Exception as e:
        logging.error(f"Failed to load model: {str(e)}")
        error_msg = f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
        if "CUDA" in str(e):
            error_msg += "\næ³¨æ„ï¼šæœªæ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†ï¼Œè¿™å¯èƒ½ä¼šå½±å“æ€§èƒ½"
        return None, error_msg

def generate_seed():
    seed = random.randint(1, 100000000)
    return {
        "__type__": "update",
        "value": seed
    }


def postprocess(speech, top_db=60, hop_length=220, win_length=440):
    speech, _ = librosa.effects.trim(
        speech, top_db=top_db,
        frame_length=win_length,
        hop_length=hop_length
    )
    if speech.abs().max() > max_val:
        speech = speech / speech.abs().max() * max_val
    speech = torch.concat([speech, torch.zeros(1, int(cosyvoice.sample_rate * 0.2))], dim=1)
    return speech


def change_instruction(mode_checkbox_group):
    return instruct_dict[mode_checkbox_group]


def generate_audio(tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                   seed, stream, speed):
    global cosyvoice  # æ·»åŠ å…¨å±€å˜é‡å£°æ˜
    
    if current_model[0] is None:
        gr.Warning('è¯·å…ˆåŠ è½½æ¨¡å‹')
        return (16000, np.zeros(16000))
    
    cosyvoice = current_model[0]  # ä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹
    
    if prompt_wav_upload is not None:
        prompt_wav = prompt_wav_upload
    elif prompt_wav_record is not None:
        prompt_wav = prompt_wav_record
    else:
        prompt_wav = None

    # æ£€æŸ¥è¾“å…¥å‚æ•°
    if not tts_text:
        gr.Warning('è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬')
        return (16000, np.zeros(16000))

    # if instruct mode, please make sure that model is iic/CosyVoice-300M-Instruct and not cross_lingual mode
    if mode_checkbox_group in ['è‡ªç„¶è¯­è¨€æ§åˆ¶']:
        if cosyvoice.instruct is False:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300M-Instructæ¨¡å‹'.format(args.model_dir))
            return (16000, np.zeros(16000))
        if instruct_text == '':
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, è¯·è¾“å…¥instructæ–‡æœ¬')
            return (16000, np.zeros(16000))
        if prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, promptéŸ³é¢‘/promptæ–‡æœ¬ä¼šè¢«å¿½ç•¥')

    # if cross_lingual mode, please make sure that model is iic/CosyVoice-300M and tts_text prompt_text are different language
    if mode_checkbox_group in ['è·¨è¯­ç§å¤åˆ»']:
        if cosyvoice.instruct is True:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, {}æ¨¡å‹ä¸æ”¯æŒæ­¤æ¨¡å¼, è¯·ä½¿ç”¨iic/CosyVoice-300Mæ¨¡å‹'.format(args.model_dir))
            return (16000, np.zeros(16000))
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥')
        if prompt_wav is None:
            gr.Warning('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·æä¾›promptéŸ³é¢‘')
            return (16000, np.zeros(16000))
        gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·ç¡®ä¿åˆæˆæ–‡æœ¬å’Œpromptæ–‡æœ¬ä¸ºä¸åŒè¯­è¨€')

    # if in zero_shot cross_lingual, please make sure that prompt_text and prompt_wav meets requirements
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»', 'è·¨è¯­ç§å¤åˆ»']:
        if prompt_wav is None:
            gr.Warning('promptéŸ³é¢‘ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptéŸ³é¢‘ï¼Ÿ')
            return (16000, np.zeros(16000))
        if torchaudio.info(prompt_wav).sample_rate < prompt_sr:
            gr.Warning('promptéŸ³é¢‘é‡‡æ ·ç‡{}ä½äº{}'.format(torchaudio.info(prompt_wav).sample_rate, prompt_sr))
            return (16000, np.zeros(16000))

    # sft mode only use sft_dropdown
    if mode_checkbox_group in ['é¢„è®­ç»ƒéŸ³è‰²']:
        if instruct_text != '' or prompt_wav is not None or prompt_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²æ¨¡å¼ï¼Œpromptæ–‡æœ¬/promptéŸ³é¢‘/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')
        if sft_dropdown == '':
            gr.Warning('æ²¡æœ‰å¯ç”¨çš„é¢„è®­ç»ƒéŸ³è‰²ï¼')
            return (16000, np.zeros(16000))

    # zero_shot mode only use prompt_wav prompt text
    if mode_checkbox_group in ['3sæé€Ÿå¤åˆ»']:
        if prompt_text == '':
            gr.Warning('promptæ–‡æœ¬ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptæ–‡æœ¬ï¼Ÿ')
            return (16000, np.zeros(16000))
        if instruct_text != '':
            gr.Info('æ‚¨æ­£åœ¨ä½¿ç”¨3sæé€Ÿå¤åˆ»æ¨¡å¼ï¼Œé¢„è®­ç»ƒéŸ³è‰²/instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼')

    try:
        if mode_checkbox_group == 'é¢„è®­ç»ƒéŸ³è‰²':
            logging.info('get sft inference request')
            set_all_random_seed(seed)
            for i in cosyvoice.inference_sft(tts_text, sft_dropdown, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        elif mode_checkbox_group == '3sæé€Ÿå¤åˆ»':
            logging.info('get zero_shot inference request')
            prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
            set_all_random_seed(seed)
            for i in cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        elif mode_checkbox_group == 'è·¨è¯­ç§å¤åˆ»':
            logging.info('get cross_lingual inference request')
            prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
            set_all_random_seed(seed)
            for i in cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
        else:
            logging.info('get instruct inference request')
            set_all_random_seed(seed)
            for i in cosyvoice.inference_instruct(tts_text, sft_dropdown, instruct_text, stream=stream, speed=speed):
                yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
    except Exception as e:
        logging.error(f"Error during audio generation: {str(e)}")
        gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        return (16000, np.zeros(16000))

def get_system_info():
    """è·å–ç³»ç»Ÿç¡¬ä»¶ä¿¡æ¯"""
    info = []
    
    # CPUä¿¡æ¯
    cpu_info = f"CPU: {platform.processor()}"
    cpu_count = psutil.cpu_count(logical=False)
    cpu_logical = psutil.cpu_count(logical=True)
    cpu_info += f" ({cpu_count} ç‰©ç†æ ¸å¿ƒ, {cpu_logical} é€»è¾‘æ ¸å¿ƒ)"
    info.append(cpu_info)
    
    # å†…å­˜ä¿¡æ¯
    memory = psutil.virtual_memory()
    memory_info = f"å†…å­˜: {memory.total / (1024**3):.1f}GB (å¯ç”¨: {memory.available / (1024**3):.1f}GB)"
    info.append(memory_info)
    
    # CUDAä¿¡æ¯
    cuda_available = torch.cuda.is_available()
    if cuda_available:
        cuda_info = f"CUDA: å¯ç”¨ (ç‰ˆæœ¬ {torch.version.cuda})"
        gpu_info = []
        for i in range(torch.cuda.device_count()):
            gpu = GPUtil.getGPUs()[i]
            gpu_info.append(f"GPU {i}: {gpu.name} ({gpu.memoryTotal}MB)")
        info.append(cuda_info)
        info.extend(gpu_info)
    else:
        info.append("CUDA: ä¸å¯ç”¨ (å°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†)")
        info.append("æ³¨æ„ï¼šä½¿ç”¨CPUè¿›è¡Œæ¨ç†å¯èƒ½ä¼šå½±å“æ€§èƒ½")
    
    # æ“ä½œç³»ç»Ÿä¿¡æ¯
    system = platform.system()
    
    # æ£€æµ‹ Windows 11
    if system == "Windows":
        try:
            import winreg
            with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Microsoft\Windows NT\CurrentVersion") as key:
                product_name = winreg.QueryValueEx(key, "ProductName")[0]
                build_number = winreg.QueryValueEx(key, "CurrentBuildNumber")[0]
                if "Windows 11" in product_name or int(build_number) >= 22000:
                    os_info = f"æ“ä½œç³»ç»Ÿ: Windows 11 (Build {build_number})"
                else:
                    os_info = f"æ“ä½œç³»ç»Ÿ: {product_name} (Build {build_number})"
        except:
            # å¦‚æœæ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨åŸºæœ¬ç³»ç»Ÿä¿¡æ¯
            os_info = f"æ“ä½œç³»ç»Ÿ: {system} {platform.release()}"
    else:
        os_info = f"æ“ä½œç³»ç»Ÿ: {system} {platform.release()}"
    
    info.append(os_info)
    
    return "\n".join(info)

def main():
    # å…¨å±€å˜é‡å£°æ˜
    global current_model, cosyvoice, prompt_sr
    current_model = [None]  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
    prompt_sr = 16000  # è®¾ç½®é‡‡æ ·ç‡

    with gr.Blocks() as demo:
        gr.Markdown("### CosyVoice è¯­éŸ³åˆæˆç³»ç»Ÿ")
        
        # ç³»ç»Ÿä¿¡æ¯æ˜¾ç¤º
        with gr.Accordion("ç³»ç»Ÿä¿¡æ¯", open=True):
            system_info = get_system_info()
            gr.Markdown(f"```\n{system_info}\n```")
        
        # ttsfrd çŠ¶æ€æ£€æŸ¥
        ttsfrd_status = check_ttsfrd_installation()
        if not TTSFRD_AVAILABLE:
            with gr.Accordion("âš ï¸ ç³»ç»Ÿæç¤º", open=True):
                gr.Markdown(ttsfrd_status)
        
        # æ¨¡å‹é€‰æ‹©å’ŒåŠ è½½éƒ¨åˆ†
        with gr.Row():
            model_dropdown = gr.Dropdown(
                choices=list(AVAILABLE_MODELS.keys()),
                label="é€‰æ‹©æ¨¡å‹",
                value=list(AVAILABLE_MODELS.keys())[0]
            )
            load_model_button = gr.Button("åŠ è½½æ¨¡å‹")
            model_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
    
        
        gr.Markdown("#### è¯·è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬ï¼Œé€‰æ‹©æ¨ç†æ¨¡å¼ï¼Œå¹¶æŒ‰ç…§æç¤ºæ­¥éª¤è¿›è¡Œæ“ä½œ")

        tts_text = gr.Textbox(label="è¾“å…¥åˆæˆæ–‡æœ¬", lines=1, value="æˆ‘æ˜¯é€šä¹‰å®éªŒå®¤è¯­éŸ³å›¢é˜Ÿå…¨æ–°æ¨å‡ºçš„ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œæä¾›èˆ’é€‚è‡ªç„¶çš„è¯­éŸ³åˆæˆèƒ½åŠ›ã€‚")
        with gr.Row():
            mode_checkbox_group = gr.Radio(choices=inference_mode_list, label='é€‰æ‹©æ¨ç†æ¨¡å¼', value=inference_mode_list[0])
            instruction_text = gr.Text(label="æ“ä½œæ­¥éª¤", value=instruct_dict[inference_mode_list[0]], scale=2)
            sft_dropdown = gr.Dropdown(
                choices=[''],  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨ï¼Œä½†åŒ…å«ä¸€ä¸ªç©ºé€‰é¡¹
                label='é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²',
                value='',  # åˆå§‹å€¼è®¾ä¸ºç©ºå­—ç¬¦ä¸²
                scale=1
            )
            stream = gr.Radio(choices=stream_mode_list, label='æ˜¯å¦æµå¼æ¨ç†', value=stream_mode_list[0][1])
            speed = gr.Number(value=1, label="é€Ÿåº¦è°ƒèŠ‚(ä»…æ”¯æŒéæµå¼æ¨ç†)", minimum=0.5, maximum=2.0, step=0.1)
            with gr.Column(scale=1):
                seed_button = gr.Button(value="\U0001F3B2")
                seed = gr.Number(value=0, label="éšæœºæ¨ç†ç§å­")

        with gr.Row():
            prompt_wav_upload = gr.Audio(sources='upload', type='filepath', label='é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæ³¨æ„é‡‡æ ·ç‡ä¸ä½äº16khz')
            prompt_wav_record = gr.Audio(sources='microphone', type='filepath', label='å½•åˆ¶promptéŸ³é¢‘æ–‡ä»¶')
        prompt_text = gr.Textbox(label="è¾“å…¥promptæ–‡æœ¬", lines=1, placeholder="è¯·è¾“å…¥promptæ–‡æœ¬ï¼Œéœ€ä¸promptéŸ³é¢‘å†…å®¹ä¸€è‡´ï¼Œæš‚æ—¶ä¸æ”¯æŒè‡ªåŠ¨è¯†åˆ«...", value='')
        instruct_text = gr.Textbox(label="è¾“å…¥instructæ–‡æœ¬", lines=1, placeholder="è¯·è¾“å…¥instructæ–‡æœ¬.", value='')

        generate_button = gr.Button("ç”ŸæˆéŸ³é¢‘")
        audio_output = gr.Audio(label="åˆæˆéŸ³é¢‘", autoplay=True, streaming=True)

        def on_model_load(model_name):
            """å¤„ç†æ¨¡å‹åŠ è½½äº‹ä»¶"""
            try:
                model, status = load_model(model_name)
                if model is not None:
                    current_model[0] = model
                    # è·å–é¢„è®­ç»ƒéŸ³è‰²åˆ—è¡¨
                    spk_list = model.list_available_spks()
                    logging.info(f"Available speakers for {model_name}: {spk_list}")
                    
                    if not spk_list:
                        logging.warning(f"No speakers found for model {model_name}")
                        return status, gr.update(choices=[''], value='')
                    
                    return status, gr.update(choices=spk_list, value=spk_list[0])
                else:
                    current_model[0] = None
                    return status, gr.update(choices=[''], value='')
            except Exception as e:
                logging.error(f"Error in on_model_load: {str(e)}")
                return f"åŠ è½½æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", gr.update(choices=[''], value='')

        def on_generate_audio(*args):
            if current_model[0] is None:
                gr.Warning('è¯·å…ˆåŠ è½½æ¨¡å‹')
                return (16000, np.zeros(16000))
            
            try:
                for audio in generate_audio(*args):
                    if isinstance(audio, tuple) and len(audio) == 2:
                        sample_rate, audio_data = audio
                        if isinstance(audio_data, np.ndarray):
                            return (sample_rate, audio_data)
                    return (16000, np.zeros(16000))
            except Exception as e:
                logging.error(f"Error during audio generation: {str(e)}")
                gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                return (16000, np.zeros(16000))

        # åœ¨é¡µé¢åº•éƒ¨æ·»åŠ è¯¦ç»†ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            # CosyVoice è¯­éŸ³åˆæˆç³»ç»Ÿä½¿ç”¨æŒ‡å—

            ## 1. ç³»ç»Ÿæ¦‚è¿°
            CosyVoice æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è¯­éŸ³åˆæˆç³»ç»Ÿï¼Œæ”¯æŒå¤šç§è¯­éŸ³åˆæˆæ¨¡å¼ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒéŸ³è‰²ã€å£°éŸ³å…‹éš†ã€è·¨è¯­ç§åˆæˆç­‰ã€‚

            ## 2. åŸºæœ¬ä½¿ç”¨æµç¨‹
            1. é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹
            2. é€‰æ‹©åˆæˆæ¨¡å¼
            3. è¾“å…¥å¿…è¦çš„ä¿¡æ¯
            4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®

            ## 3. æ¨¡å‹è¯´æ˜
            ### 3.1 CosyVoice-300M
            - **åŠŸèƒ½ç‰¹ç‚¹**ï¼šåŸºç¡€æ¨¡å‹ï¼Œæ”¯æŒå¤šè¯­è¨€åˆæˆå’Œå£°éŸ³å…‹éš†
            - **é€‚ç”¨åœºæ™¯**ï¼šä¸€èˆ¬è¯­éŸ³åˆæˆã€å£°éŸ³å…‹éš†
            - **æ”¯æŒè¯­è¨€**ï¼šä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰

            ### 3.2 CosyVoice-300M-SFT
            - **åŠŸèƒ½ç‰¹ç‚¹**ï¼šé¢„è®­ç»ƒéŸ³è‰²æ¨¡å‹ï¼Œæä¾›å¤šç§é¢„è®¾éŸ³è‰²
            - **é€‚ç”¨åœºæ™¯**ï¼šå›ºå®šéŸ³è‰²æ’­æŠ¥ã€æœ‰å£°ä¹¦æœ—è¯»
            - **ç‰¹è‰²**ï¼šéŸ³è‰²ç¨³å®šï¼Œå‘éŸ³å‡†ç¡®

            ### 3.3 CosyVoice-300M-Instruct
            - **åŠŸèƒ½ç‰¹ç‚¹**ï¼šæŒ‡ä»¤æ§åˆ¶æ¨¡å‹ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æ§åˆ¶
            - **é€‚ç”¨åœºæ™¯**ï¼šæƒ…æ„Ÿè¯­éŸ³ã€æ–¹è¨€è¯­éŸ³
            - **ç‰¹è‰²**ï¼šæ”¯æŒè¯­æ°”ã€æƒ…æ„Ÿã€æ–¹è¨€ç­‰æ§åˆ¶

            ### 3.4 CosyVoice2-0.5B
            - **åŠŸèƒ½ç‰¹ç‚¹**ï¼šæœ€æ–°ç‰ˆæœ¬ï¼Œæä¾›æ›´å¼ºå¤§çš„è¯­éŸ³åˆæˆèƒ½åŠ›
            - **é€‚ç”¨åœºæ™¯**ï¼šé«˜è´¨é‡è¯­éŸ³åˆæˆã€å®æ—¶è¯­éŸ³ç”Ÿæˆ
            - **ç‰¹è‰²**ï¼šæ›´é«˜çš„è¯­éŸ³è´¨é‡ï¼Œæ›´è‡ªç„¶çš„è¯­éŸ³è¡¨ç°

            ## 4. åˆæˆæ¨¡å¼è¯´æ˜
            ### 4.1 é¢„è®­ç»ƒéŸ³è‰²
            - **ä½¿ç”¨æ­¥éª¤**ï¼š
                1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²
                2. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬
                3. ç‚¹å‡»ç”ŸæˆæŒ‰é’®
            - **é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦å›ºå®šéŸ³è‰²çš„åœºæ™¯

            ### 4.2 3sæé€Ÿå¤åˆ»
            - **ä½¿ç”¨æ­¥éª¤**ï¼š
                1. ä¸Šä¼ æˆ–å½•åˆ¶å‚è€ƒéŸ³é¢‘ï¼ˆä¸è¶…è¿‡30ç§’ï¼‰
                2. è¾“å…¥å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬
                3. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬
                4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®
            - **é€‚ç”¨åœºæ™¯**ï¼šä¸ªæ€§åŒ–è¯­éŸ³ç”Ÿæˆ

            ### 4.3 è·¨è¯­ç§å¤åˆ»
            - **ä½¿ç”¨æ­¥éª¤**ï¼š
                1. ä¸Šä¼ æˆ–å½•åˆ¶å‚è€ƒéŸ³é¢‘
                2. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬ï¼ˆä¸å‚è€ƒéŸ³é¢‘ä¸åŒè¯­è¨€ï¼‰
                3. ç‚¹å‡»ç”ŸæˆæŒ‰é’®
            - **é€‚ç”¨åœºæ™¯**ï¼šå¤šè¯­è¨€è¯­éŸ³åˆæˆ

            ### 4.4 è‡ªç„¶è¯­è¨€æ§åˆ¶
            - **ä½¿ç”¨æ­¥éª¤**ï¼š
                1. é€‰æ‹©é¢„è®­ç»ƒéŸ³è‰²
                2. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬
                3. è¾“å…¥æ§åˆ¶æŒ‡ä»¤ï¼ˆå¦‚ï¼šç”¨å››å·è¯è¯´è¿™å¥è¯ï¼‰
                4. ç‚¹å‡»ç”ŸæˆæŒ‰é’®
            - **é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦ç‰¹å®šè¯­æ°”æˆ–é£æ ¼çš„åœºæ™¯

            ## 5. é«˜çº§åŠŸèƒ½
            ### 5.1 æµå¼æ¨ç†
            - **åŠŸèƒ½è¯´æ˜**ï¼šå®æ—¶ç”ŸæˆéŸ³é¢‘ï¼Œé€‚åˆå®æ—¶åº”ç”¨
            - **ä½¿ç”¨å»ºè®®**ï¼šéœ€è¦å®æ—¶åé¦ˆæ—¶å¼€å¯

            ### 5.2 é€Ÿåº¦è°ƒèŠ‚
            - **åŠŸèƒ½è¯´æ˜**ï¼šè°ƒæ•´è¯­éŸ³åˆæˆé€Ÿåº¦
            - **ä½¿ç”¨èŒƒå›´**ï¼š0.5-2.0å€é€Ÿ
            - **æ³¨æ„**ï¼šä»…æ”¯æŒéæµå¼æ¨ç†æ¨¡å¼

            ### 5.3 éšæœºç§å­
            - **åŠŸèƒ½è¯´æ˜**ï¼šæ§åˆ¶è¯­éŸ³ç”Ÿæˆçš„éšæœºæ€§
            - **ä½¿ç”¨å»ºè®®**ï¼šéœ€è¦å›ºå®šç”Ÿæˆç»“æœæ—¶ä½¿ç”¨

            ## 6. é£æ ¼æ§åˆ¶ç¤ºä¾‹
            ### 6.1 æƒ…æ„Ÿè¡¨è¾¾
            - **å¼€å¿ƒè¯­æ°”**ï¼š
                ```
                ç”¨å¼€å¿ƒçš„è¯­æ°”è¯´ï¼šå‚åŠ æœ‹å‹çš„å©šç¤¼ï¼Œçœ‹ç€æ–°äººå¹¸ç¦çš„ç¬‘è„¸ï¼Œæˆ‘æ„Ÿåˆ°æ— æ¯”å¼€å¿ƒã€‚è¿™æ ·çš„çˆ±ä¸æ‰¿è¯ºï¼Œæ€»æ˜¯ä»¤äººå¿ƒç”Ÿå‘å¾€ã€‚
                ```
            - **ä¼¤å¿ƒè¯­æ°”**ï¼š
                ```
                ç”¨ä¼¤å¿ƒçš„è¯­æ°”è¯´ï¼šæ”¶åˆ°æ‹’ä¿¡çš„é‚£ä¸€åˆ»ï¼Œæˆ‘æ„Ÿåˆ°æ— æ¯”ä¼¤å¿ƒã€‚è™½ç„¶çŸ¥é“å¤±è´¥æ˜¯æˆé•¿çš„ä¸€éƒ¨åˆ†ï¼Œä½†ä»ç„¶éš¾ä»¥æ©é¥°å¿ƒä¸­çš„å¤±è½ã€‚
                ```
            - **æƒŠè®¶è¯­æ°”**ï¼š
                ```
                ç”¨æƒŠè®¶çš„è¯­æ°”è¯´ï¼šèµ°è¿›å®¶é—¨ï¼Œçœ‹è§å¢™ä¸ŠæŒ‚æ»¡äº†æˆ‘çš„ç…§ç‰‡ï¼Œæˆ‘æƒŠè®¶å¾—æ„£ä½äº†ã€‚åŸæ¥å®¶äººæ‚„æ‚„ä¸ºæˆ‘å‡†å¤‡äº†ä¸€ä¸ªæƒŠå–œçš„çºªå¿µå¢™ã€‚
                ```
            - **ç”Ÿæ°”è¯­æ°”**ï¼š
                ```
                ç”¨ç”Ÿæ°”çš„è¯­æ°”è¯´ï¼šåœ¨äº¤é€šé«˜å³°æœŸï¼Œé­é‡åˆ°ä¸€ä½é²è½çš„å¸æœºæ’é˜Ÿï¼Œæˆ‘æ„Ÿåˆ°éå¸¸ç”Ÿæ°”ã€‚è¿™ç§ä¸æ–‡æ˜çš„è¡Œä¸ºæ€»è®©äººæ— å¥ˆã€‚
                ```

            ### 6.2 è¯­é€Ÿæ§åˆ¶
            - **å¿«é€Ÿ**ï¼š
                ```
                å¿«é€Ÿï¼šè¿™æ¬¾æ–°åº”ç”¨ç¨‹åºåŠ è½½é€Ÿåº¦æå¿«ï¼Œè®©ç”¨æˆ·ä½“éªŒå¾—åˆ°äº†æå¤§çš„æå‡ï¼Œä½¿ç”¨èµ·æ¥æ›´åŠ æµç•…ä¾¿æ·ã€‚
                ```
            - **æ…¢é€Ÿ**ï¼š
                ```
                æ…¢é€Ÿï¼šå¬ç€è½»æŸ”çš„éŸ³ä¹ï¼Œæˆ‘åœ¨ç”»å¸ƒä¸Šæ…¢æ…¢åœ°æ¶‚æŠ¹è‰²å½©ï¼Œè®©æ¯ä¸€ç¬”éƒ½å……æ»¡çµæ„Ÿå’Œæ€è€ƒã€‚
                ```

            ### 6.3 è¯­æ°”æ§åˆ¶
            - **å†·é™**ï¼š
                ```
                å†·é™ï¼šåœ¨äº‰è®ºä¸­ï¼Œæˆ‘è¯•å›¾è®©è‡ªå·±å†·é™ä¸‹æ¥ï¼Œç†æ™ºåœ°è¡¨è¾¾æˆ‘çš„è§‚ç‚¹ã€‚åªæœ‰å†·é™ï¼Œæ‰èƒ½æœ‰æ•ˆæ²Ÿé€šã€‚
                ```
            - **ä¸¥è‚ƒ**ï¼š
                ```
                ä¸¥è‚ƒï¼šè¿™ä¸ªå®‰å…¨éšæ‚£é—®é¢˜å¿…é¡»ä¸¥è‚ƒå¤„ç†ï¼Œæˆ‘ä»¬ä¸èƒ½æ‰ä»¥è½»å¿ƒï¼Œå¿…é¡»é‡‡å–æœ‰æ•ˆæªæ–½åŠ ä»¥è§£å†³ã€‚
                ```

            ### 6.4 è·¨è¯­è¨€ç¤ºä¾‹
            - **ä¸­æ–‡åˆ°è‹±æ–‡**ï¼š
                ```
                åŸæ–‡ï¼šä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œè®©äººå¿ƒæƒ…æ„‰æ‚¦ã€‚
                è‹±æ–‡ï¼šThe weather is beautiful today, with bright sunshine that lifts everyone's spirits.
                ```
            - **è‹±æ–‡åˆ°ä¸­æ–‡**ï¼š
                ```
                åŸæ–‡ï¼šReading is a journey that allows you to explore new worlds.
                ä¸­æ–‡ï¼šé˜…è¯»æ˜¯ä¸€æ¬¡è®©ä½ æ¢ç´¢æ–°ä¸–ç•Œçš„æ—…ç¨‹ã€‚
                ```

            ## 7. æ³¨æ„äº‹é¡¹
            1. éŸ³é¢‘æ–‡ä»¶é‡‡æ ·ç‡éœ€è¦ä¸ä½äº16kHz
            2. å»ºè®®éŸ³é¢‘é•¿åº¦ä¸è¶…è¿‡30ç§’
            3. ç¡®ä¿è¾“å…¥æ–‡æœ¬ä¸å‚è€ƒéŸ³é¢‘å†…å®¹ä¸€è‡´
            4. è·¨è¯­ç§åˆæˆæ—¶æ³¨æ„è¯­è¨€é€‰æ‹©
            5. ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ—¶æ³¨æ„æŒ‡ä»¤çš„å‡†ç¡®æ€§

            ## 8. å¸¸è§é—®é¢˜
            ### 8.1 æ¨¡å‹åŠ è½½å¤±è´¥
            - æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
            - ç¡®è®¤CUDAç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®

            ### 8.2 éŸ³é¢‘ç”Ÿæˆå¤±è´¥
            - æ£€æŸ¥è¾“å…¥å‚æ•°æ˜¯å¦å®Œæ•´
            - ç¡®è®¤éŸ³é¢‘æ ¼å¼æ˜¯å¦æ­£ç¡®
            - æŸ¥çœ‹é”™è¯¯æç¤ºä¿¡æ¯

            ### 8.3 æ€§èƒ½é—®é¢˜
            - ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
            - å…³é—­æµå¼æ¨ç†
            - å‡å°éŸ³é¢‘é•¿åº¦

            ## 9. æŠ€æœ¯æ”¯æŒ
            å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ”¯æŒï¼š
            1. æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£
            2. æäº¤Issue
            3. åŠ å…¥ç”¨æˆ·äº¤æµç¾¤
            """)

        # ç»‘å®šäº‹ä»¶
        load_model_button.click(
            on_model_load,
            inputs=[model_dropdown],
            outputs=[model_status, sft_dropdown]
        )
        
        seed_button.click(generate_seed, inputs=[], outputs=seed)
        generate_button.click(
            on_generate_audio,
            inputs=[tts_text, mode_checkbox_group, sft_dropdown, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                    seed, stream, speed],
            outputs=[audio_output]
        )
        mode_checkbox_group.change(fn=change_instruction, inputs=[mode_checkbox_group], outputs=[instruction_text])

    demo.queue(max_size=4, default_concurrency_limit=2)
    demo.launch(server_name='0.0.0.0', server_port=args.port, inbrowser=True)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--port',
                        type=int,
                        default=8000)
    args = parser.parse_args()
    main()
